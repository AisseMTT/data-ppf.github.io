{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Lab 5\n",
    " # Yuletide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Late in the nineteenth century, Udny Yule was concerned to investigate the \"various causes that one may conceive to effect changes in the rate of pauperism.\"\n",
    "\n",
    "In particular, Yule wanted to clarify the role, if any, of differing amounts of \"out-relief\" in causing greater pauperism. The [Poor Laws of 1834](http://www.workhouses.org.uk/poorlaws/newpoorlaw.shtml) were to discourage the population from \"wanting\" to be poor, by forcing anyone deemed capable of working in workhouses with deliberately harsh conditions.  \"out-relief,\" the granting of funds for survival, was to be forbidden to all able-bodied adults and the families, in favor of \"In-relief\" for those working in such workhouses. \n",
    "\n",
    "\n",
    "Yule's original paper: Yule, G. Udny. 1899. [\"An Investigation into the Causes of Changes in Pauperism in England, Chiefly during the Last Two Intercensal Decades.\"](http://www.jstor.org.ezproxy.cul.columbia.edu/stable/2979889) *Journal of the Royal Statistical Society* 62 (Part II):249-295. \n",
    "\n",
    "He doesn't give all his data, but gives one important example. \n",
    "\n",
    "![example](https://i.imgur.com/7DTIfZK.png). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pauper_data=pd.read_csv(\"https://raw.githubusercontent.com/data-ppf/data-ppf.github.io/master/labs/lab5/Yule_tableXIX.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pauper_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a scatter matrix, something not readily available to Mr. Yule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(pauper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares and Regression\n",
    "\n",
    "Thanks to high level packages, it's very, very easy to do simple linear regression using least squares.  \n",
    "\n",
    "Linear Regression IN GENERAL:\n",
    "\n",
    "$y = \\beta_n x_n + ... + \\beta_1 x_1 + \\mu_0$\n",
    "\n",
    "Linear Regression FOR JUST ONE VARIABLE:\n",
    "\n",
    "$y = \\beta_1 x_1 + \\mu$ \n",
    "\n",
    "where $\\beta_1$ is the slope, $x$ are the observations, and $\\mu$ is the y-intercept.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, friends, let's regress for a minute. Let's try connecting just two of the variables in the scatter plot above.\n",
    "What do you choose?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regression_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this, we must identify the value to be predicted (called y) and the data to be used to do the predicting (called X). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pauper_data[\"out\"] # this will be subsequently known as our training data or training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=X.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pauper_data[\"paup\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these choices, we ask `sklearn` to use the `LinearRegression()` to fit the data to produce the data. Poor Mr. Yule would have had someone to do all this by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y,  color='black')\n",
    "plt.plot(X, regression_model.predict(X), color='blue', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.predict(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".35 is, let's say, not a strong vote in favor in our model. This is $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn: regress a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariable regressing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Mr. Yule, was concerned that something else might be the underlying cause of the changes in outrelief. \n",
    "\n",
    "![Yule_multiple](https://i.imgur.com/go8cXCd.png)\n",
    "\n",
    "\n",
    "We can undertake something like his analysis with ease, using almost identical syntax.\n",
    "\n",
    "\n",
    "First, let's make `X` all the columns EXCEPT the `paup` data. `X` can be one column or multiple ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pauper_data.drop(\"paup\", axis=1)   \n",
    "\n",
    "# axis=1 means a column in this context. Almost no one ever remembers which is column and which rows, so just check yer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, for `y` just that first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pauper_data[\"paup\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fit our model, using the same syntax as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is finding all the $\\beta_i$ in the general linear regression\n",
    "\n",
    "$y = \\beta_n x_n + ... + \\beta_1 x_1 + \\mu_0$\n",
    "\n",
    "\n",
    "Within `sklearn`, we can find those $\\beta_i$ coefficients using the `.coef_` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".70? 'Zwounds, we've discovered rock-bottom truth!\n",
    "\n",
    "\n",
    "Note for the reader: Yule gives slightly different values (.755, -.022 and -.322) than rederivations.  \n",
    "\n",
    "Here's how Yule presents his coefficients:\n",
    "\n",
    "![Yule coefficients](https://i.imgur.com/3IiDti3.png)\n",
    "\n",
    "\n",
    "Yule concludes his paper, with a series of claims quoted by Desrosieres:\n",
    "\n",
    "![Yule conclusions](https://i.imgur.com/3TwxM3G.png) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Freedman reading challenges Yule's conclusions.\n",
    ">At best, Yule has established association. Conditional on the covariates, there is a positive association between  $\\Delta$Paup and $\\Delta$Out. Is this association causal? If so, which way do the causal arrows point? For instance, a parish may choose not to build poor- houses in response to a short-term increase in the number of paupers. Then pauperism is the cause and outrelief the effect. Likewise, the number of paupers in one area may well be affected by relief policy in neighboring areas. Such issues are not resolved by the data analysis. Instead, answers are assumed *a priori*. Although he was busily parceling out changes in pauperism – so much is due to changes in out-relief ratios, so much to changes in other variables, so much to random effects – Yule was aware of the difficulties. With one deft footnote (number 25), he withdrew all causal claims: ‘Strictly speaking, for “due to” read “associated with”.’\n",
    "\n",
    "![Yule weasel](https://i.imgur.com/r7ZPsKH.png)\n",
    "\n",
    "The causal situation is deeply problematic, as Freedman explains:\n",
    ">To make causal inferences, it must be assumed that equations are stable under proposed interventions. Verifying such assumptions – without making the interventions – is problematic. On the other hand, if the coefficients and error terms change when variables are manipulated, the equation has only a limited utility for predicting the results of interventions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
