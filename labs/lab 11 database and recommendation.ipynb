{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Past, Present, Future\n",
    "## Lab 11\n",
    "## Databases and recommendation engines\n",
    "\n",
    "\n",
    "> Campaigns are moving away from the meaningless labels of pollsters and newsweeklies — “Nascar dads” and “waitress moms” — and moving toward treating each voter as a separate person. In 2012 you didn’t just have to be an African-American from Akron or a suburban married female age 45 to 54. More and more, the information age allows people to be complicated, contradictory and unique. New technologies and an abundance of data may rattle the senses, but they are also bringing a fresh appreciation of the value of the individual to American politics.\n",
    "\n",
    "Ethan Roeder, [“I Am Not Big Brother”](http://www.nytimes.com/2012/12#/06/opinion/i-am-not-big-brother.html?_r=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## connecting people and the long tail\n",
    "\n",
    ">In 1988, a British mountain climber named Joe Simpson wrote a book called *Touching the Void*, a harrowing account of near death in the Peruvian Andes. It got good reviews but, only a modest success, it was soon forgotten. Then, a decade later, a strange thing happened. Jon Krakauer wrote *Into Thin Air*, another book about a mountain-climbing tragedy, which became a publishing sensation. Suddenly *Touching the Void* started to sell again. . .. \n",
    "\n",
    "> What happened? In short, Amazon.com recommendations. The online bookseller's software noted patterns in buying behavior and suggested that readers who liked *Into Thin Air* would also like *Touching the Void*. People took the suggestion, agreed wholeheartedly, wrote rhapsodic reviews. More sales, more algorithm-fueled recommendations, and the positive feedback loop kicked in.\n",
    "\n",
    "Chris Anderson, [The Long Tail](https://www.wired.com/2004/10/tail/)\n",
    "                \n",
    "![long tail](https://media.wired.com/photos/5a59579a5451ae3d197fcf65/master/w_650,c_limit/FF_170_tail2_f.gif)\n",
    "\n",
    "![long tail connection](https://media.wired.com/photos/5a5957cf2bbf59566d73366b/master/w_550,c_limit/FF_170_tail6_f.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix prize\n",
    "\n",
    "In 2009, BellKor's Pragmatic Chaos won the Netflix Prize for building a superior movie recommender system.\n",
    "\n",
    "![winners](https://graphics8.nytimes.com/images/2009/09/21/technology/netflixawards.480.jpg)\n",
    "\n",
    "\n",
    "\n",
    "![netflix prize](https://i.imgur.com/6TUm2Yj.png)\n",
    "\n",
    "\n",
    "\n",
    "(see the cached version at https://web.archive.org/web/20070202023620/http://www.netflixprize.com:80/rules)\n",
    "\n",
    "\n",
    "Netflix data set:\n",
    "\n",
    "> 5-star ratings on 17770 movies and 480189 anonymous users over ~7 years. total of 100480507 ratings\n",
    "\n",
    "A good deal of commerical data to use machine learning on, collected over time by the ordinary actions of users. Potentially telling us an awful lot about users\n",
    "\n",
    "\n",
    "We'll try a smaller data set. We won't win a million dollars.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the MovieLens data set with 100K ratings from http://grouplens.org/datasets/movielens/. For now, it's available to you locally. There you can find much bigger sets.\n",
    "\n",
    "(Compare a great blog post using `pandas` on the same data: http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/.) The approach and tools are slightly different. Worth checking out!\n",
    "\n",
    "You need to have a directory ml-100k in the same place as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to look at three files: u.data, u.item, u.user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![relational](http://imgur.com/ZhpRFTj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relational database\n",
    "\n",
    ">[The relational model] organizes data into one or more tables (or \"relations\") of columns and rows, with a unique key identifying each row. \n",
    "\n",
    ">each table/relation represents one \"entity type\" (such as customer or product). The rows represent instances of that type of entity (such as \"Lee\" or \"chair\") and the columns representing values attributed to that instance (such as address or price). (h/t wikipedia)\n",
    "\n",
    "Created by E. F. Cobb at IBM around 1969, see https://dl.acm.org/citation.cfm?doid=362384.362685\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films=pd.read_csv('./ml-100k/u.item', sep=\"|\", names=[\"movie id\", \"movie_title\", \"release_date\", \"video_release_date\", \"IMDb_URL\", \"unknown\", \"Action\",\"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"], index_col=\"movie id\", encoding=\"latin1\")\n",
    "\n",
    "users=pd.read_csv('./ml-100k/u.user', sep=\"|\", names=[\"user_id\", \"age\", \"gender\",\"occupation\",\"zip_code\"], index_col=\"user_id\")\n",
    "\n",
    "individual_ratings=pd.read_csv( './ml-100k/u.data', sep=\"\\t\", names=[\"user_id\",\"item_id\",\"rating\",\"timestamp\"]) #\\t because TAB separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's with that crazy number? According to the `README`, it's \"unix seconds.\" A quick google search explains how to convert using the `pd.to.datetime` command. I will remember this just long enough to type the next few lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is said that 95% of data analysis is fussing or munging the data. This is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "individual_ratings[\"timestamp\"]=pd.to_datetime(individual_ratings[\"timestamp\"], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is nice. \n",
    "\n",
    "What if we wanted to get all the items that one user ranked?\n",
    "\n",
    "\n",
    "We could use \"boolean indexing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.loc[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films.loc[102]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did Mr. administrator # 42 rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[\"user_id\"]==42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we're in the confort zone with boolean indexing, we'd probably condense all that into one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[individual_ratings[\"user_id\"]==42]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might we profile user 42 based on this data? Think of three ways and do one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[individual_ratings[\"user_id\"]==42]['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` lets us do all sorts of simple statistics, like finding the mean. just tack on the method `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[individual_ratings[\"user_id\"]==42]['rating'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about all the ratings for a given film, say no. 65? \n",
    "\n",
    "How would we get that? \n",
    "\n",
    "Same idea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[individual_ratings[\"item_id\"]==65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we get the average rating for film 65?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[individual_ratings[\"item_id\"]==65][\"rating\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we might want to know something about there's a lot of variation in views about the film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_ratings[individual_ratings[\"item_id\"]==65][\"rating\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas as a powerful database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## SPLIT-APPLY-COMBINE\n",
    "\n",
    "> - Splitting the data into groups based on some criteria\n",
    "> - Applying a function to each group independently\n",
    "> - Combining the results into a data structure\n",
    "\n",
    "check the docs!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![SPLIT](http://i.imgur.com/yjNkiwL.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.groupby(by=[\"occupation\", \"gender\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot\n",
    "\n",
    "\n",
    "What if we wanted to have a big table where each row is the user followed by all her ratings?\n",
    "We could write a few lines of code to produce this.\n",
    "\n",
    "Fortunately, Pandas will do this heavy lifting for us using the `pivot` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings=individual_ratings.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically: rework our data using user_id as row names; item_id as column names and all the ratings as the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[100:115]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Why all the NaNs?\n",
    "\n",
    "\n",
    "#### Another question to the user: Why not switch all the NaNs to zeros?\n",
    "\n",
    "\n",
    "This is called a *sparse* matrix: most of the values are empty. \n",
    "\n",
    "Most large scale commerical rating or purchasing data looks like this. Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question: What did we lose from our original dataframe?\n",
    "\n",
    "### Question: What questions could no longer ask?\n",
    "\n",
    "- say we wanted to know whether people rate movies differently at different times of the day? or differently during different seasons?.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now easily ask about the mean ratings of each user, and the mean ratings of each movie? \n",
    "\n",
    "How would we do these operations differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which movies are not garbage according to the masses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.mean(0)>4.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the_good_stuff=ratings.mean(0)>4.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And where would we find the names of these films?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films[the_good_stuff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How find the bad stuff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool!\n",
    "What are the average ratings per user?\n",
    "\n",
    "We need to use `mean` across columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.mean(1) #average rating per user axis 1 is rows--user ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.mean(1)>4 # axis 1 is rows--user ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "those_lacking_discernment=ratings.mean(1)>4\n",
    "pretentious_movie_snobs=ratings.mean(1)<2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some of things we might want to do with our knowledge of the users and their rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[those_lacking_discernment].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[4].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[pretentious_movie_snobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.loc[206].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the teenager from Delavan, WI not hate? Could you figure it out? \n",
    "\n",
    "And, if we were Netflix, what would we want to recommed to her?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What might we want to do with our new knowledge\n",
    "\n",
    "Let's discount the less discerning viewers! Let's just lower their rankings by .75. A bit arbitrary, but so are they!\n",
    "\n",
    "We could multiply every element in a dataframe by a constant like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[those_lacking_discernment]*.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Recommending stuff\n",
    "\n",
    "Lots of strategies.\n",
    "Any ideas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most similar *users*\n",
    "Find most similar *items*\n",
    "\n",
    "Use data from users to recommend items: called *collaborative filtering*.\n",
    "\n",
    "Combine them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine  #cosine distance function--not cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(A,B):\n",
    "    return 1 - cosine(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity((1,0),(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity((1,2),(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity([1,1,0],[0,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([np.mean(ratings, 1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those NaNs are trouble. \n",
    "\n",
    "One way to normalize is to subtract each users' mean rating for his or her row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.mean(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings.fillna(0).sub(pd.Series(ratings.mean(axis=1)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings_normalized=ratings.fillna(0).sub(pd.Series(ratings.mean(axis=1)), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can compare users to users and movies to movies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(ratings_normalized.loc[24], ratings_normalized.loc[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the similarities, we'll pick one film (#1) and compute the cosine similarity with every other film. What's number one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarities(film):\n",
    "    similarities={}\n",
    "    for i in range(1,944):\n",
    "         similarities[i]=cosine_similarity(ratings_normalized.loc[film], ratings_normalized.loc[i])\n",
    "    return pd.Series(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similarities(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are the most similar films according to this crazy way of proceeding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similarities(1).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films['movie_title'][find_similarities(1).sort_values(ascending=False).head().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(film, number=5):\n",
    "    most=films['movie_title'][find_similarities(film).sort_values(ascending=False).head(number).index]\n",
    "    print(most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(143)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the most promising approach!!\n",
    "\n",
    "For a good survey of recommending engines at scale, see the chapter from the [Stanford mining massive data course](http://infolab.stanford.edu/~ullman/mmds/ch9.pdf)\n",
    "\n",
    "\n",
    "Major problem: too high a dimensional space to use lots of algorithms efficiently!\n",
    "\n",
    "Trick: reduce dimensionality using aspects of films and users!\n",
    "\n",
    "Version of principal component analysis called SVD.\n",
    "\n",
    "SVD decomposes a large matrix into three components:\n",
    "\n",
    "![SVD diagram](http://xieyan87.com/wp-content/uploads/2015/06/SVD.png)\n",
    "\n",
    "\n",
    "Allows you to generate *latent factors* and then calculate similarities. \n",
    "\n",
    "![latent factor](https://image.slidesharecdn.com/petroniphdthesispresentation-161104150721/95/mining-at-scale-with-latent-factor-models-for-matrix-completion-8-638.jpg?cb=1478272108)\n",
    "\n",
    "Serious vs. escapist\n",
    "geared-male vs. geared-female\n",
    "&c.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ratings_normalized.values.T / np.sqrt(len(films) - 1)\n",
    "U, S, V = np.linalg.svd(A)\n",
    "\n",
    "# modified from numpy focused https://alyssaq.github.io/2015/20150426-simple-movie-recommender-using-svd/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose how many factors to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k=25\n",
    "pd.DataFrame(V.T[:, :k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarities(film, sliced):\n",
    "    similarities={}\n",
    "    for i in range(1,944):\n",
    "         similarities[i]=cosine_similarity(sliced[film-1], sliced[i-1])\n",
    "    return pd.Series(similarities)\n",
    "\n",
    "def most_similar(film, sliced, number=5):\n",
    "    most=films['movie_title'][find_similarities(film, sliced).sort_values(ascending=False).head(number).index]\n",
    "    print(most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "movie_id = 1 # Grab an id from movies.dat\n",
    "top_n = 10\n",
    "\n",
    "sliced = V.T[:, :k] # representative data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "find_similarities(1,sliced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar(405, sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Netflix challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![winners](https://graphics8.nytimes.com/images/2009/09/21/technology/netflixawards.480.jpg)\n",
    "\n",
    "Very close--came down to which group submitted first!\n",
    "\n",
    "![leaderboard](https://cdn0.tnwcdn.com/wp-content/blogs.dir/1/files/2012/04/NFlix-520x285.png)\n",
    "\n",
    "## Social ensemble of teams competing.\n",
    "\n",
    "![venn](https://i1.wp.com/s3-ap-northeast-1.amazonaws.com/wpstoragepublicshare/netflix/bellkor_team.png)\n",
    "\n",
    "## Algorithmic ensemble \n",
    "\n",
    "![bellkordiagram](https://i.imgur.com/cHXxYIl.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Huge** victory of predictive machine learning values!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But meanwhile...\n",
    "\n",
    "![dumpster_fire](https://media1.tenor.com/images/2b68afa54bb22fbe90f9201dfaaa2af0/tenor.gif?itemid=7182596)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FAQ](https://web.archive.org/web/20070202024240/https://www.netflixprize.com/faq) for Netflix Challenge reads:\n",
    "\n",
    ">“Is there any customer information in the dataset that should be kept private?” \n",
    "    \n",
    ">“No, all customer identifying information has been removed; all that remains are ratings and dates. This follows our privacy policy [. . . ] Even if, for example, you knew all your own ratings and their dates you probably couldn’t identify them reliably in the data because only a small sample was included (less than one tenth of our complete dataset) and that data was subject to perturbation. Of course, since you know all your own ratings that really isn’t a privacy problem is it?”\n",
    "\n",
    "# Sorry, nope. Not so much.\n",
    "\n",
    "\n",
    "Arvind Narayanan and Vitaly Shmatikov then of UT Austin\n",
    "\n",
    "showed \n",
    "\n",
    ">an adversary who knows only a little bit about\n",
    "an individual subscriber can easily identify this subscriber’s\n",
    "record in the [Netflix] dataset. Using the Internet\n",
    "Movie Database as the source of background knowledge,\n",
    "we successfully identified the Netflix records of\n",
    "known users, uncovering their apparent political preferences\n",
    "and other potentially sensitive information.\n",
    "\n",
    "\n",
    "[Robust De-anonymization of Large Datasets](https://www.cs.utexas.edu/~shmat/shmat_oak08netflix.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How does all this lead to more\n",
    "\n",
    "![dumpster_fire](https://media1.tenor.com/images/2b68afa54bb22fbe90f9201dfaaa2af0/tenor.gif?itemid=7182596)\n",
    "\n",
    "glory of recommender engines:\n",
    "\n",
    "> long tail\n",
    "- connect people who may have never known one another\n",
    "- connect people with things they might never have known\n",
    "\n",
    "disaster of recommender enginers:\n",
    "\n",
    "> put like with like: filter bubble\n",
    "\n",
    "Political twitter according to [\"Political Polarization on Twitter\"](http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/download/2847/3275)\n",
    "\n",
    "![polarization](http://themonkeycage.org/wp-content/uploads/2011/07/Screen-shot-2011-07-27-at-11.23.29-AM.png)\n",
    "\n",
    "political retweet (left) and mention (right) networks, laid out using a force-directed algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
