{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Past, Present, Future\n",
    "# Lab 8 AI without the ML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"History makes the present strange\"\n",
    ">-- James Grimmelman, after a talk about this class, Feb. 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most valuable things about history is pointing out how things could have been, as they say, the other way. For example, today AI and ML (machine learning) are used nearly interchangably. It was not at all clear in the early days of AI that successes in AI would come from machines that learn in the presence of data. One idea, in part inspired by WWII crypto, was heuristic-empowered search. That is, many problems in life can be abstracted as search problems, in which the space of possible results is quite large. One early meaning of heuristics was rules and procedures that would help limit the search space to a few viable candidate best responses or solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build \"AI\" we need only create an algorithm that imitates a natural intelligence -- not an algorithm whose performance improves when presented with additional data (the latter being one of the canonical definitions of machine learning, which we will get to soon)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help illustrate the diversity of research in AI during the 1950-1973 period, let's look at the chat program [Eliza](https://en.wikipedia.org/wiki/ELIZA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ELIZA is an early natural language processing computer program created from 1964 to 1966[1] at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum\n",
    "> --Wikipdedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's try Eliza, then look at the [source code.](https://github.com/nltk/nltk/blob/develop/nltk/chat/eliza.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliza is so canonical it is included as part of [NLTK](https://en.wikipedia.org/wiki/Natural_Language_Toolkit), so the \"import antigravity\" for this exercise is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nltk.chat.eliza.demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliza is one of several chatbots in NLTK. For fun, try some of these--of check out how the code works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.chat.iesha.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.chat.rude.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.chat.suntsu.demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.chat.zen.demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might also enjoy reading it in the near-original [Lisp](https://en.wikipedia.org/wiki/Lisp_(programming_language%29), as coded by [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) [here](https://github.com/norvig/paip-lisp/blob/master/lisp/eliza1.lisp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You may remember the character *Animal* from the Muppets. \n",
    "![groot](https://akns-images.eonline.com/eol_images/Entire_Site/2014817/rs_1024x759-140917065659-1024.Groot-JR-91714.jpg?fit=inside|900:auto&output-quality=90) \n",
    "\n",
    "Groot has limited lexical complexity. Colloquy with Groot takes this form, taken from Guardians of the Galaxy, part II:\n",
    "\n",
    ">When Yondu and Rocket find themselves in the mutineering Ravagers' brig, they enlist Baby Groot's help to get Yondu's prototype fin. It doesn't go well.\n",
    "\n",
    ">The following conversation ensues:\n",
    "\n",
    ">Yondu: \"What? No!\"\n",
    "\n",
    ">Rocket: \"He thinks you want him to wear it as a hat.\"\n",
    "\n",
    ">Yondu: \"That's not what I said!\"\n",
    "\n",
    ">Groot: \"I am Groot.\"\n",
    "\n",
    ">Rocket: \"He's relieved that you don't want him to.\"\n",
    "\n",
    ">Groot: \"I am Groot.\"\n",
    "\n",
    ">Rocket: \"He hates hats.\"\n",
    "\n",
    ">Groot: \"I am Groot.\"\n",
    "\n",
    ">Rocket: \"On anyone, not just himself.\"\n",
    "\n",
    ">Groot: \"I am Groot.\"\n",
    "\n",
    ">Rocket: \"You see someone and think they have a weird head and then it just turns out part of their head is a hat. That's why you don't like hats?\"\n",
    "\n",
    "Let's look at the code for Eliza in python. \n",
    "\n",
    "Consider this bit of code from Eliza. How might you make an Groot chatbot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair=\n",
    "(r'Why can\\'t I (.*)',\n",
    "  ( \"Do you think you should be able to %1?\",\n",
    "    \"If you could %1, what would you do?\",\n",
    "    \"I don't know -- why can't you %1?\",\n",
    "\"Have you really tried?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The appearance of *originality* was central to the concerns of the early figures of AI. How does the code for Eliza build in something to give some appearance of a non-mechanical quality?\n",
    "\n",
    "Find the \"respond\" function in the code common to all these bots.\n",
    "\n",
    "[chat utility](https://github.com/nltk/nltk/blob/develop/nltk/chat/util.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expert Systems: the example of Mycin\n",
    "\n",
    "\n",
    "> \"MYCIN is the original expert system that made it evident to all the rest of the world that a new niche had opened up. . . . MYCIN epitomized the new path that had been created.\"--Allen Newell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem\n",
    "\n",
    "> The \"antimicrobial revolution\" began with the introduction of the sulfonamides in the 1930s and penicillin in 1943. The beneficial effects that these and subsequent drugs have had on humanity cannot be overstated. However, as early as the 1950s it became clear that antibiotics were being misused. A study of office practice involving 87 general practitioners (Peterson et al., 1956) revealed that antibiotics were given indiscriminately to all patients with upper respiratory infections by 67% of the physicians, while only 33% ever tried to separate viral from bacterial etiologies. \n",
    "\n",
    "So, the best expert knowledge in the medical profession wasn't in practice. What to do about this?\n",
    "\n",
    "Expert system architecture:\n",
    "\n",
    "![architecture](https://i.imgur.com/7cM8VqL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an expert system, knowledge engineers collaborate with domain experts to create by hand the \"knowledge base\" upon which the \"inference engine operates.\" Rule 036, for example, in LISP and then in English reads:\n",
    "\n",
    "\n",
    ">RULE036\n",
    "\n",
    ">PREMISE: ($AND (SAME CNTXT GRAM GRAMNEG)\n",
    "\n",
    ">               (SAME CNTXTM MORPH ROD)\n",
    "\n",
    ">               (SAME CNTXT AIR ANAEROBIC))\n",
    "\n",
    ">ACTION: (CONCLUDE CNTXT IDENTITY BACTEROIDES TALLY 0.6)\n",
    "\n",
    ">IF: 1) The gram stain of the organism is gramneg, and\n",
    "\n",
    ">    2) The morphology of the organism is rod, and\n",
    "\n",
    ">    3) The aerobicity of the organism is anaerobic\n",
    "\n",
    ">THEN: There is suggestive evidence (0.6) that the identity of the organism is *bacteroides*\n",
    "\n",
    "\"Suggestive evidence\" is a subjective probability, a quantification of the beliefs of a medical expert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the code for the \"knowledge base\" portion of a python implementation of mycin.\n",
    "\n",
    "https://github.com/dhconnelly/paip-python/blob/master/paip/examples/emycin/mycin.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/dhconnelly/paip-python/master/paip/examples/emycin/mycin.py\n",
    "\"\"\"\n",
    "Mycin: a medical expert system.\n",
    "\n",
    "This is a small example of an expert system that uses the\n",
    "[Emycin](../../emycin.html) shell.  It defines a few contexts, parameters, and\n",
    "rules, and presents a rudimentary user interface to collect data about an\n",
    "infection in order to determine the identity of the infecting organism.\n",
    "\n",
    "In a more polished system, we could:\n",
    "\n",
    "- define and use a domain-specific language for the expert;\n",
    "- present a more polished interface, perhaps a GUI, for user interaction;\n",
    "- offer a data serialization mechanism to save state between sessions.\n",
    "\n",
    "This implementation comes from chapter 16 of Peter Norvig's \"Paradigms of\n",
    "Artificial Intelligence Programming.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "### Utility functions\n",
    "\n",
    "def eq(x, y):\n",
    "    \"\"\"Function for testing value equality.\"\"\"\n",
    "    return x == y\n",
    "\n",
    "def boolean(string):\n",
    "    \"\"\"\n",
    "    Function for reading True or False from a string.  Raises an error if the\n",
    "    string is not True or False.\n",
    "    \"\"\"\n",
    "    if string == 'True':\n",
    "        return True\n",
    "    if string == 'False':\n",
    "        return False\n",
    "    raise ValueError('bool must be True or False')\n",
    "\n",
    "\n",
    "### Setting up initial data\n",
    "\n",
    "# Here we define the contexts, parameters, and rules for our system.  This is\n",
    "# the job of the expert, and in a more polished system, we would define and use\n",
    "# a domain-specific language to make this easier.\n",
    "\n",
    "def define_contexts(sh):\n",
    "    # Patient and Culture have some initial goals--parameters that should be\n",
    "    # collected before reasoning begins.  This might be useful in some domains;\n",
    "    # for example, this might be legally required in a medical system.\n",
    "    sh.define_context(Context('patient', ['name', 'sex', 'age']))\n",
    "    sh.define_context(Context('culture', ['site', 'days-old']))\n",
    "    \n",
    "    # Finding the identity of the organism is our goal.\n",
    "    sh.define_context(Context('organism', goals=['identity']))\n",
    "\n",
    "def define_params(sh):\n",
    "    # Patient params\n",
    "    sh.define_param(Parameter('name', 'patient', cls=str, ask_first=True))\n",
    "    sh.define_param(Parameter('sex', 'patient', enum=['M', 'F'], ask_first=True))\n",
    "    sh.define_param(Parameter('age', 'patient', cls=int, ask_first=True))\n",
    "    sh.define_param(Parameter('burn', 'patient',\n",
    "                              enum=['no', 'mild', 'serious'], ask_first=True))\n",
    "    sh.define_param(Parameter('compromised-host', 'patient', cls=boolean))\n",
    "    \n",
    "    # Culture params\n",
    "    sh.define_param(Parameter('site', 'culture', enum=['blood'], ask_first=True))\n",
    "    sh.define_param(Parameter('days-old', 'culture', cls=int, ask_first=True))\n",
    "    \n",
    "    # Organism params\n",
    "    organisms = ['pseudomonas', 'klebsiella', 'enterobacteriaceae',\n",
    "                 'staphylococcus', 'bacteroides', 'streptococcus']\n",
    "    sh.define_param(Parameter('identity', 'organism', enum=organisms, ask_first=True))\n",
    "    sh.define_param(Parameter('gram', 'organism',\n",
    "                              enum=['acid-fast', 'pos', 'neg'], ask_first=True))\n",
    "    sh.define_param(Parameter('morphology', 'organism', enum=['rod', 'coccus']))\n",
    "    sh.define_param(Parameter('aerobicity', 'organism', enum=['aerobic', 'anaerobic']))\n",
    "    sh.define_param(Parameter('growth-conformation', 'organism',\n",
    "                              enum=['chains', 'pairs', 'clumps']))\n",
    "\n",
    "def define_rules(sh):\n",
    "    sh.define_rule(Rule(52,\n",
    "                        [('site', 'culture', eq, 'blood'),\n",
    "                         ('gram', 'organism', eq, 'neg'),\n",
    "                         ('morphology', 'organism', eq, 'rod'),\n",
    "                         ('burn', 'patient', eq, 'serious')],\n",
    "                        [('identity', 'organism', eq, 'pseudomonas')],\n",
    "                        0.4))\n",
    "    sh.define_rule(Rule(71,\n",
    "                        [('gram', 'organism', eq, 'pos'),\n",
    "                         ('morphology', 'organism', eq, 'coccus'),\n",
    "                         ('growth-conformation', 'organism', eq, 'clumps')],\n",
    "                        [('identity', 'organism', eq, 'staphylococcus')],\n",
    "                        0.7))\n",
    "    sh.define_rule(Rule(73,\n",
    "                        [('site', 'culture', eq, 'blood'),\n",
    "                         ('gram', 'organism', eq, 'neg'),\n",
    "                         ('morphology', 'organism', eq, 'rod'),\n",
    "                         ('aerobicity', 'organism', eq, 'anaerobic')],\n",
    "                        [('identity', 'organism', eq, 'bacteroides')],\n",
    "                        0.9))\n",
    "    sh.define_rule(Rule(75,\n",
    "                        [('gram', 'organism', eq, 'neg'),\n",
    "                         ('morphology', 'organism', eq, 'rod'),\n",
    "                         ('compromised-host', 'patient', eq, True)],\n",
    "                        [('identity', 'organism', eq, 'pseudomonas')],\n",
    "                        0.6))\n",
    "    sh.define_rule(Rule(107,\n",
    "                        [('gram', 'organism', eq, 'neg'),\n",
    "                         ('morphology', 'organism', eq, 'rod'),\n",
    "                         ('aerobicity', 'organism', eq, 'aerobic')],\n",
    "                        [('identity', 'organism', eq, 'enterobacteriaceae')],\n",
    "                        0.8))\n",
    "    sh.define_rule(Rule(165,\n",
    "                        [('gram', 'organism', eq, 'pos'),\n",
    "                         ('morphology', 'organism', eq, 'coccus'),\n",
    "                         ('growth-conformation', 'organism', eq, 'chains')],\n",
    "                        [('identity', 'organism', eq, 'streptococcus')],\n",
    "                        0.7))\n",
    "\n",
    "\n",
    "### Running the system\n",
    "\n",
    "import logging\n",
    "from paip.emycin import Parameter, Context, Rule, Shell\n",
    "\n",
    "def report_findings(findings):\n",
    "    for inst, result in findings.items():\n",
    "        print 'Findings for %s-%d:' % (inst[0], inst[1])\n",
    "        for param, vals in result.items():\n",
    "            possibilities = ['%s: %f' % (val[0], val[1]) for val in vals.items()]\n",
    "            print '%s: %s' % (param, ', '.join(possibilities))\n",
    "        \n",
    "def main():\n",
    "    sh = Shell()\n",
    "    define_contexts(sh)\n",
    "    define_params(sh)\n",
    "    define_rules(sh)\n",
    "    report_findings(sh.execute(['patient', 'culture', 'organism']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you find the rules hand-coded into the program?\n",
    "\n",
    "Copy one and express it into English as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits of Expert Systems and yet another AI winter\n",
    "\n",
    "Jack Schwartz, appointed director of Information Systems Technology Office (ISTO) within DARPA. \n",
    "\n",
    "In his [1987 encylopedia entry \"Limits of Artificial Intelligence\"](https://archive.org/details/limitsofartifici00schw), he savaged existing AI. As for expert systems, well,\n",
    "\n",
    "> Overall, we can say that expert systems enhance their pragmatic \n",
    "applicability by narrowing the traditional goals of artificial intelligence \n",
    "research substantially, and by blurring the distinction between clever \n",
    "specialized programming and use of unifying principles of self-organization \n",
    "applicable across a wide variety of domains. This makes their significance \n",
    "for future development of deeper artificial intelligence technologies entirely \n",
    "debatable in spite of their hoped-for pragmatic utility.\n",
    "\n",
    "Schwartz \"fell on\" DARPA funded Expert Systems programs \"like a rider out of the Apocalypse.\" (Roland, 205)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Acquisition Bottleneck and the limits of expert systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major problem: MYCIN took twenty person-years to produce just 475 rules (Roland)\n",
    "\n",
    ">“Mastery is not acquired by reading books—it’s acquired by trial-and-error and teacher supplied examples. This is how humans acquire skill. People are very reluctant to accept this.  Their reluctance tells us something about the philosophical self image that we, as thinking beings, prefer. It tells us nothing about what actually happens when a teacher or a master trains somebody. That somebody has to regenerate rules from example to make them an intimate part of his intuitive skill.”  (Professor Donald Michie, “Expert Systems Interview,” Expert Systems 2, no. 1 (1985): 22.)\n",
    "\n",
    "Machine learning often escapes just this problem: \n",
    "\n",
    ">the machine learning technique takes advantage of the data and avoids the knowledge acquisition bottleneck by extracting classification rules directly from data. Rather than asking an expert for domain knowledge, a machine learning algorithm observes expert tasks and induces rule emulating expert decisions. (Keki B. Irani et al., “Applying Machine Learning to Semiconductor Manufacturing,” IEEE Expert 8, no. 1 (1993): 41.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
