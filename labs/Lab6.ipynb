{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Past, Present, Future\n",
    "## Lab 6: statistical testing and p-value hacking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will work with some data sets concerning physical attributes of brains and measures of intelligence. Collectively you will undertake a series of statistical examinations AND you will also reflect critically on the data sets in question, the literature about them, and the licitness of different computational operations on data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher's experimental program\n",
    "\n",
    "Why significance testing? What solution to the problem of empirical knowledge is it, particularly in the Fisherian form? What solutions to the creation of knowledge does that program reject?\n",
    "\n",
    "Download a few pages from Fisher's [*Design of Experiments*](http://www.phil.vt.edu/dmayo/PhilStatistics/b%20Fisher%20design%20of%20experiments.pdf)\n",
    "\n",
    "What is the problem of \"inverse probabilility\" discussed on pp. 4-5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes: $P(H\\mid E) = \\frac{P(E\\mid H) \\cdot P(H)}{P(E)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does Fisher so reject Bayes as a solution on 6-7?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What's the central problem with $P(H)$ for many observers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is experimental work essential to the liberation of the human intellect at p. 9?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do tests of signficance around a null hypothesis offer a solution to the problem of knowledge at 15?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally what justification for \"p<.05\" on p. 13? How does *Fisher* state p<.05?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to doing some of this in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# usual preliminaries\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use\n",
    "plt.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some data. This data set is used in boatloads of intro stats courses and online tutorials, particularly of the extremely mechanical sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('http://www.scipy-lectures.org/_downloads/brain_size.csv', sep=';', na_values=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using standard pandas and other statistical functions, start describing this data set.\n",
    "\n",
    "FYI The test includes evaluation of several forms of IQ: Full-Scale IQ (FSIQ) score, which is based on Verbal IQ (VIQ) and a Performance IQ (PIQ). (Use the interwebs to find out what these are.)\n",
    "\n",
    "\n",
    "Examples might include .mean(), .describe(), boxplots and so forth. What and where are the outliers?\n",
    "\n",
    "For example, you can draw a box plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"PIQ\"].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try doing some comparisons of male and female brains and IQs, because nothing is more hard wired into social science than doing so. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's not forget some exploratory data analysis using exciting graphical functions. Make a scatter matrix for starters.\n",
    "Because I'm nice, I'll get you going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can't possibly be looking at that scatter matrix without itching to do some regressions, right? \n",
    "\n",
    "Of course, right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, go crazy with some regressions and get back to me. Maybe do some more EDA to look for interesting correlations among subsets of the data. High IQ, low IQ, men, women, tall, short, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-tests\n",
    "\n",
    "t-tests, t-tests I hear you cry. We got your t-tests. \n",
    "\n",
    "They are found in the `stats` package within `scipy`.\n",
    "\n",
    "\n",
    "Let's look at the documentation and do some.\n",
    "\n",
    "\n",
    "First figure out the difference between st.ttest_1samp() and stats.ttest_ind(). \n",
    "\n",
    "Use the ? to get documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a t-test. Just run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_1samp(data['VIQ'], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this `mean`? What has been done? How should it be interpreted? How would our friend Fisher understand this: what would the null hypothesis be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try a slighter harder one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.ttest_1samp(data['FSIQ'] - data['PIQ'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the question being asked here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to your Gould readings. What might he counsel in thinking about this paper and this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## let's back up and look at the paper\n",
    "\n",
    "\n",
    "\n",
    "Reflect  on the data set we are using. What important questions must be kept in mind while using this data set?\n",
    "\n",
    "Willerman, Lee, Robert Schultz, J. Neal Rutledge, and Erin D. Bigler. “In Vivo Brain Size and Intelligence.” Intelligence 15, no. 2 (1991): 223–228. https://doi.org/10.1016/0160-2896(91)90031-8\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to reproduce at least one of their results. For many of their results, you may need to find out how to perform ANCOVA in python, but let's stick to t-tests for now, unless you already know ANCOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who has cited and used this paper? Find at least one example, and discuss their reflections upon it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recent meta-analysis\n",
    "\n",
    "go to http://www.sciencedirect.com/science/article/pii/S014976341500250X\n",
    "\n",
    "What's the story they offer about \"Publication bias\" (in section 3.1.4.3.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you find the data with any of the more recent studies cited in that metaanalysis to attempt to replicate a result? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-value hacking\n",
    "\n",
    "> Goodhart's Law: “when a measure become a target, it is no longer a measure“\n",
    "\n",
    "Let's say you're looking to publish a nice result with the right sort of p-value. For p-values hacking, see, e.g., http://www.nature.com/news/scientific-method-statistical-errors-1.14700 Can you, um, 'manufacture' such a result by tailoring the data set? Give it the old school try.\n",
    "\n",
    "Go to the tool called \"Hack Your Way to Scientific Glory\" at\n",
    "\n",
    "https://fivethirtyeight.com/features/science-isnt-broken/#part1\n",
    "\n",
    "\n",
    "What did you manage to show was significant p<.05?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p-value hacking fun \n",
    "\n",
    "For super extra fun with p-value hacking, get a key paper on the subject \n",
    "\n",
    "http://journals.sagepub.com/doi/figure/10.1177/0956797611417632?\n",
    "\n",
    "and then the data\n",
    "\n",
    "https://zenodo.org/record/7664\n",
    "\n",
    "\n",
    "Check out their second result: \n",
    "\n",
    ">According to their birth dates, people were nearly a year-and-a-half younger after listening to “When I’m Sixty-Four” (adjusted M = 20.1 years) rather than to “Kalimba” (adjusted M = 21.5 years), F(1, 17) = 4.92, p = .040.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between their description of the experiment and the way they present the process in their Table 3? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Another very controversial example comes from \n",
    "\n",
    "> Bem, Daryl J. “Feeling the Future: Experimental Evidence for Anomalous Retroactive Influences on Cognition and Affect.” Journal of Personality and Social Psychology 100, no. 3 (2011): 407–25. https://doi.org/10.1037/a0021524.\n",
    "\n",
    "Check out experiment one. The data is [here]( https://replicationindex.wordpress.com/2018/01/20/my-email-correspondence-with-daryl-j-bem-about-the-data-for-his-2011-article-feeling-the-future/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_data=pd.read_excel('https://replicationindex.files.wordpress.com/2018/01/exp1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either data set, try at least four tests to attempt to fish for a significant (p<.05) result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is to be done? \n",
    "\n",
    "The authors suggest\n",
    ">We propose the following six requirements for authors.\n",
    "\n",
    ">    Authors must decide the rule for terminating data collection before data collection begins and report this rule in the article. Following this requirement may mean reporting the outcome of power calculations or disclosing arbitrary rules, such as “we decided to collect 100 observations” or “we decided to collect as many observations as we could before the end of the semester.” The rule itself is secondary, but it must be determined ex ante and be reported.\n",
    "\n",
    ">    Authors must collect at least 20 observations per cell or else provide a compelling cost-of-data-collection justification. This requirement offers extra protection for the first requirement. Samples smaller than 20 per cell are simply not powerful enough to detect most effects, and so there is usually no good reason to decide in advance to collect such a small number of observations. Smaller samples, it follows, are much more likely to reflect interim data analysis and a flexible termination rule. In addition, as Figure 1 shows, larger minimum sample sizes can lessen the impact of violating Requirement 1.\n",
    "\n",
    ">    Authors must list all variables collected in a study. This requirement prevents researchers from reporting only a convenient subset of the many measures that were collected, allowing readers and reviewers to easily identify possible researcher degrees of freedom. Because authors are required to just list those variables rather than describe them in detail, this requirement increases the length of an article by only a few words per otherwise shrouded variable. We encourage authors to begin the list with “only,” to assure readers that the list is exhaustive (e.g., “participants reported only their age and gender”).\n",
    "\n",
    ">    Authors must report all experimental conditions, including failed manipulations. This requirement prevents authors from selectively choosing only to report the condition comparisons that yield results that are consistent with their hypothesis. As with the previous requirement, we encourage authors to include the word “only” (e.g., “participants were randomly assigned to one of only three conditions”).\n",
    "\n",
    ">    If observations are eliminated, authors must also report what the statistical results are if those observations are included. This requirement makes transparent the extent to which a finding is reliant on the exclusion of observations, puts appropriate pressure on authors to justify the elimination of data, and encourages reviewers to explicitly consider whether such exclusions are warranted. Correctly interpreting a finding may require some data exclusions; this requirement is merely designed to draw attention to those results that hinge on ex post decisions about which data to exclude.\n",
    "\n",
    ">    If an analysis includes a covariate, authors must report the statistical results of the analysis without the covariate. Reporting covariate-free results makes transparent the extent to which a finding is reliant on the presence of a covariate, puts appropriate pressure on authors to justify the use of the covariate, and encourages reviewers to consider whether including it is warranted. Some findings may be persuasive even if covariates are required for their detection, but one should place greater scrutiny on results that do hinge on covariates despite random assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
