{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Past, Present, Future\n",
    "# Lab 12a: Fairness, accountability, transparency (continued)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The [\"seductive diversion\"](https://medium.com/s/story/the-seductive-diversion-of-solving-bias-in-artificial-intelligence-890df5e5ef53) of fairness\n",
    "\n",
    ">Serious thinkers in academia and business have swarmed to the A.I. bias problem, eager to tweak and improve the data and algorithms that drive artificial intelligence. They’ve latched onto fairness as the objective, obsessing over competing constructs of the term that can be rendered in measurable, mathematical form. If the hunt for a science of computational fairness was restricted to engineers, it would be one thing. But given our contemporary exaltation and deference to technologists, it has limited the entire imagination of ethics, law, and the media as well.\n",
    "\n",
    "...\n",
    "\n",
    ">In short, the preoccupation with narrow computational puzzles distracts us from the far more important issue of the colossal asymmetry between societal cost and private gain in the rollout of automated systems. It also denies us the possibility of asking: Should we be building these systems at all?\n",
    "\n",
    "-- Julia Powles and Helen Nussembaum\n",
    "\n",
    "![powles](https://cdn-images-1.medium.com/max/2000/1*cgcqBdxRpPIzhJ0lbQB81g.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transparency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ripped from the headlines\n",
    "\n",
    "Let's consider the following proposed [legislation](https://www.scribd.com/document/405606873/Detour-Act-Final):\n",
    "\n",
    ">UNFAIR AND DECEPTIVE ACTS AND PRACTICES RELATING TO THE MANIPULATION OF USER INTERFACES.\n",
    "\n",
    ">(a) CONDUCT PROHIBITED\n",
    "\n",
    ">(1) IN GENERAL\n",
    "\n",
    ">It shall be unlawful for any large online operator—\n",
    "\n",
    ">(A) to design, modify, or manipulate a user interface with the purpose or substantial effect of obscuring, subverting, or impairing user autonomy, decision-making, or choice to obtain consent or user data; \n",
    "\n",
    ">(B) to subdivide or segment consumers of online services into groups for the purposes of behavioral or psychological experiments or studies, except with the informed consent of each user involved; \n",
    "\n",
    "[....]\n",
    "\n",
    "Introduced by U.S. Sens. Mark R. Warner (D-VA) and Deb Fischer (R-NE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are the CEO of Rent-Seekers-R-US, LLC, and it's time to optimize your privacy policies and user interface to ensure that users are maximally assured of their privacy while enabling you to monetize your data collection, both for your immediate use and for sale or exchange with third parties.\n",
    "\n",
    "So let's get <s>evil</s> monetizing. \n",
    "\n",
    "Let's find some models.\n",
    "\n",
    "Let's look at some privacy and data collection policies:\n",
    "\n",
    "+ What kinds of data are being collected? How many different kinds of data?\n",
    "+ What service or feature is enabled by the data they are collecting? Why are they collecting it in the first place?\n",
    "+ Who else is given access to that data? How are they using it?\n",
    "+ Can you get access to your own data?\n",
    "+ What do they have to do if they change their policies?\n",
    "\n",
    "Let's start with *Slack*, which is surely being provided for us to use for free out of the goodness of the investors' hearts.\n",
    "\n",
    "https://slack.com/privacy-policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And most crucially, *how* does the presentation of the policy potentially *obfuscate* answers to these questions.\n",
    "\n",
    "Now go on the big scary open web and find examples of egregious legal language or user interface (\"UX\" for the cogniscenti) in the slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you examples where the policies sound fairly innocuous until one is equipped with a better understanding of current technologies? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accountability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "####  [Principles for Accountable Algorithms](http://www.fatml.org/resources/principles-for-accountable-algorithms)\n",
    ">Automated decision making algorithms are now used throughout industry and government, underpinning many processes from dynamic pricing to employment practices to criminal sentencing. . . . Accountability in this context includes an obligation to report, explain, or justify algorithmic decision-making as well as mitigate any negative social impacts or potential harms.  \n",
    "\n",
    "What do you think of this definition? Does it need more or less? What does it need? Compare with the proposed legislation above? What might you do differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
