{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3  | Classifying People \n",
    "### Assigned Friday, 6 Apr 2018  /  Due Monday, 16 Apr  2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal:\n",
    "Using unsupervised learning we're going to construct a classifer by examining individual language usage. Next we're going to use this classifier to predict the political affliation of a group of people. Finally, we're going to use this exercise to reflect, analyze, and explore how such practices both reify and challenge our contemporary understanding of community and the public discourse. \n",
    "\n",
    "More specifically, you're going to\n",
    "1. Tokenize and get word counts for a set of tweets;\n",
    "2. see how these twitter user accounts cluster based on word usage using PCA;\n",
    "3. explore how word usage is (or isn't) a good proxy for political affliation for people in public office.\n",
    "\n",
    "#### To do this homework, you will also need the following files (which are also provided in github with this homework):\n",
    "1. 2016tweets.csv (which is 19 MB so be sure you have a good internet connection!) \n",
    "2. pol_aff.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Problems \n",
    "#### This assignment is to be done on your own. Provide your code to justify your answer to each question.  Be sure to rename this homework so that it includes your name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Getting Word Frequencies For All Words in each tweet\n",
    "\n",
    "### question 1 [1 points]\n",
    "Ingest the file 2016tweets.csv into pandas as a dataframe entitled \"tweets\". Note that each tweet is a row. (You can find this file in the github repo in the same folder as this homework.) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 2 [4 points]\n",
    "1. What day and time was the oldest tweet in the data set posted? Hint: use `tweets['created_at'].min()`.\n",
    "2. What day and time was the most recent tweet in the data set posted?\n",
    "3. How many *tweets* does the data set have? \n",
    "4. How many unique twitter users does the data set have? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 3 [30 points]\n",
    "Use *sklearn's CountVectorizer* to produce a table of word counts in which each tweet is a row and each word is a column. Name this table \"wc\".\n",
    "\n",
    "For a simple example of using sklearn countvectorizer to produce a table like this, see below. Note that this example just uses three made-up tweets so that it's easier to see what's happening.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'animal': 0, 'can': 1, 'is': 2, 'large': 3, 'the': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Here we list a few sample strings, where each \n",
    "# string can be considered one text. For the tweets \n",
    "# dataframe you'll to produce a list in which each tweet is one string.  \n",
    "# The string \"The animal is large\" is text 0 below; the string\n",
    "# \"is is is\" is text 1 below; etc.\n",
    "three_tweets= [\"The animal is large.\", \"is is is\", \"The can't\"]\n",
    "\n",
    "# create vectorizer \n",
    "cv = CountVectorizer()\n",
    "\n",
    "# tokenize texts & get vocabulary\n",
    "cv.fit(three_tweets) #note that the sklearn tokenizer turns \"can't\" into \"can\"\n",
    "\n",
    "# create a dictionary where each word is given an index number.\n",
    "# If you need to know what word a number represents, refer back to this dictionary\n",
    "word_index = cv.vocabulary_\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find out what column number a particular word is, say, \"animal\" we can use \n",
    "word_index[\"animal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a table of tweets vs words\n",
    "word_counts =  cv.transform(three_tweets)\n",
    "\n",
    "# and get the \"shape\" of this table like this:\n",
    "word_counts.shape\n",
    "# where the 3 rows are the three tweets and the \n",
    "# 5 columns are the 5 words in this corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 1],\n",
       "       [0, 0, 3, 0, 0],\n",
       "       [0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, you can dump the word_counts table into an array\n",
    "# where each row is a tweet, each column is a word type, and each\n",
    "# element is a word token count (where each word is denoted by a number\n",
    "# as defined in the word_index). For difference between word types and word tokens, \n",
    "# see \"type-token distinction\" in wikipedia.\n",
    "wc = word_counts.toarray()\n",
    "wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to substitute the \"three_texts\" list with a list of all the tweets that appear in your data set.\n",
    "\n",
    "#### Put your code for question 3 below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find word usage for each twitter account\n",
    "\n",
    "### question 4 [20 points]\n",
    "The table wc give us the word counts for all tweets, but what we really want is a table of word counts *for all twitter accounts in our data set* (i.e., word counts for all tweets for each account).  \n",
    "\n",
    "Make a new table called \"wc_accounts\" where each row is a twitter account user and the columns are word token counts for unique word types. (Note 2:  In the dataframe \"tweets\", a \"user_id\" is provided for each tweet.) You'll probably want to generate wc_accounts using a for loop that \n",
    "1. adds all the word counts in all the tweets written by the same account \n",
    "2. writes these account word counts to a new row;\n",
    "3. and then repeats for all twitter accounts in corpus. \n",
    "\n",
    "However, as usual, there's more than one way to do this. Do whatever way makes most sense to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Put your code for question 4 below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Perform PCA on wc_accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have wc_acounts, we'd like to plot this to see how all these accounts use language. But how plot this in two dimensions? Let's use a form of unsupervised learning called PCA, where each account (i.e., each row) represents one data point. This is effectivey the same as the PCA we performed on the Iris and Spearman data sets in lab 5. And we can plot our twitter account data in exactly in the same way we did then.   \n",
    "\n",
    "However, we have one additional wrinkle in our task. It'd be helpful to know which political affliation each individual twitter account has. Fortunately, I have this data for you! In pol_aff.csv I have included user_ID and their respective political affliation. Use this csv to get the political association of each user account. Note that this file may include user_IDs that don't exist in your corpus of tweets so you'll need to selective add political affliation based on user IDs. \n",
    "\n",
    "### question 5 [25 points]\n",
    "Perform PCA on individual user accounts using the data in wc_accounts. Plot this in 2 dimensions where each data point represents one twitter account. Color code each data point according to account political affliation, with red = republicans and blue = democrats. To make overlapping data points easier to see, reduce the opacity (i.e., the \"alpha\" parameter) to 0.3. \n",
    "\n",
    "\n",
    "#### Put your code for question 5 below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Reflection: Choose your own adventure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide an answer to either question 6 or question 7 but not both.\n",
    "\n",
    "\n",
    "### question 6 [30 points, 350 words max] --  Post-Analysis Reflection: Using language to track political affliation\n",
    "Write a short reflection about what you did in steps 1 - 3, specifically focusing on what assumptions are required for us to see language usage as a meaningful proxy for political affliation. The point is not to say what assumptions you agree with; but rather what would you have to believe to take the results of this investigation seriously. Are these assumptions tenable for inferring political affliation? Your answer will be graded on style, clarity, insight, and creativity.\n",
    "\n",
    "Be sure to address the following questions in your answer:\n",
    "1. Via visual inspection of your PCA plot in step 3, does our analysis of word usage effectively identify political affliations?  \n",
    "2. What are some ways in which we could use *subsets of the vocabulary* as a better proxy for political affliation? How? What new problems might this cause? Are there other ways this proxy might be improved?\n",
    "3. From step 1, you know what time period these tweets span. How might this influence the results of clustering by political affliation? How might you \n",
    "4. From lab 5, we saw that when applied to texts, PCA was sensitive to word length of texts being examined, i.e., longer texts tended to cluster together and shorter texts tended to cluster together. Without actually doing the analysis, how might you check to see if this was influencing your results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### question 7 [30 points, 350 words max] --  Unsupervised learning proxies as a way of imagining communties\n",
    "We looked at tweets in this assignment as a way of tracking political affliation, but one could apply these and other unsupervised learning techniques to group people in other ways. In our case clustering (and possible subsequent classification or categorization) is produced by an examination of the simularity of word usage--even though there is no obvious or necessary connection between word usage and political affliation. We could examine any set of features (not just words) to cluster groups of people, look for what particular features \"produce\" clusters that make sense to us (using a test set to check our clusters, such as we did above with Democrats and Republicans), and then use these particular features to group new people (i.e., those whose political affliations we do not have data). \n",
    "\n",
    "Identify at least 4 problems with grouping people in this way. What are some of the assumptions required to group people using unsupervised learning as described in the above paragraph? Be sure to address the role of the corpus in constructing groups, and the various ethical considerations tied to this choice. You may wish to address the different contexts in which this grouping of people may occur. Feel free to cite any other examples of using undersupervised learning to construct groups of people to support your argument as well as any secondary literature you feel appropriate. Your answer will be graded on style, clarity, insight, and creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
